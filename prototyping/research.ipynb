{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84115edb",
   "metadata": {},
   "source": [
    "# German Startup Newsletter Research Pipeline\n",
    "\n",
    "This notebook implements an automated research pipeline for generating a German startup newsletter. The system uses AI agents to:\n",
    "\n",
    "1. **Research** - Find recent German startup news articles using Google Search\n",
    "2. **Analyze** - Summarize and evaluate article relevance using AI\n",
    "3. **Report** - Generate a structured newsletter with insights\n",
    "\n",
    "The pipeline leverages multiple AI models and tools to create a comprehensive, automated news gathering and reporting system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a42438",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "This section initializes the research pipeline with:\n",
    "\n",
    "- **Environment Setup**: Loading environment variables and configuring Langfuse for observability\n",
    "- **MCP Server Configuration**: Setting up the Serper MCP server for Google Search API access\n",
    "\n",
    "The system uses Langfuse for tracing and monitoring the AI agent interactions, providing visibility into the research process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents.mcp import MCPServerStdio\n",
    "from datetime import datetime\n",
    "from agents import Agent, Runner, trace\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "import nest_asyncio\n",
    "from openinference.instrumentation.openai_agents import OpenAIAgentsInstrumentor\n",
    "from langfuse import get_client\n",
    "from pydantic import BaseModel\n",
    "import asyncio\n",
    " \n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Setup Langfuse\n",
    "OpenAIAgentsInstrumentor().instrument()\n",
    "langfuse = get_client()\n",
    " \n",
    "# Verify connection\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse client is authenticated and ready!\")\n",
    "else:\n",
    "    print(\"Authentication failed. Please check your credentials and host.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bfb1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "serper_mcp_server_params = {\"command\": \"uvx\", \"args\": [ \"serper-mcp-server\" ], \"env\": {\n",
    "        \"SERPER_API_KEY\": os.getenv(\"SERPER_API_KEY\"),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885dd193",
   "metadata": {},
   "source": [
    "## Data Models and Structures\n",
    "\n",
    "This section defines the Pydantic models that structure the data flow through the pipeline:\n",
    "\n",
    "- **Article**: Basic article information (title, date, URL)\n",
    "- **ResearchResults**: Container for multiple articles from research\n",
    "- **ArticleSummary**: Extended article with AI-generated summary\n",
    "- **ArticleEvaluation**: Relevance scoring and topic matching\n",
    "- **ArticleReport**: Final comprehensive article report\n",
    "\n",
    "These models ensure type safety and consistent data structure throughout the research pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article(BaseModel):\n",
    "    title: str\n",
    "    date: str\n",
    "    url: str\n",
    "\n",
    "class ResearchResults(BaseModel):\n",
    "    articles: list[Article]\n",
    "\n",
    "class ResearchResultsEvaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    acceptable_articles: list[Article]\n",
    "    reason: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135dd8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleSummary(BaseModel):\n",
    "    title: str\n",
    "    date: str\n",
    "    url: str\n",
    "    summary: str\n",
    "\n",
    "class ArticleEvaluation(BaseModel):\n",
    "    relevance_score: float\n",
    "    best_matching_topic: str\n",
    "\n",
    "class ArticleReport(BaseModel):\n",
    "    title: str\n",
    "    date: str\n",
    "    url: str\n",
    "    summary: str\n",
    "    relevance_score: float\n",
    "    best_matching_topic: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b022c1",
   "metadata": {},
   "source": [
    "## Research Agent Configuration\n",
    "\n",
    "This section configures the research agent with:\n",
    "\n",
    "- **Search Parameters**: Google Search settings (language, number of results, time filter)\n",
    "- **Search Queries**: Multiple German startup-related search terms\n",
    "- **Agent Instructions**: Detailed prompts for the research agent to find relevant articles\n",
    "\n",
    "The research agent uses the Serper MCP server to execute Google News searches and compile a list of relevant German startup articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff24147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You are a highly efficient 'Search & Discovery' agent for a startup news team. Your sole purpose is to find the most recent and relevant news articles about German startups.\"\n",
    "request = f\"Use the `google_search_news` with the following parameters: \\\n",
    "            `hl = en, de`, `num=20` and `tbs=qdr:w` \\\n",
    "            **Your Plan:** \\\n",
    "            1. Execute the following query: `Startups germany`, `Startups Deutschland`, `Finanzierungsrunden Startups Deutschland` \\\n",
    "            2. Compile a list of the 10 most relevant and unique articles \\\n",
    "            5. Return the list articles.\"\n",
    "\n",
    "model = \"gpt-4.1-nano\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5e3fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research function\n",
    "from langfuse import observe\n",
    "\n",
    "@observe(name=\"research-agent - researching articles\")\n",
    "async def research_article_urls(instructions: str, request: str) -> list[Article]:\n",
    "    async with MCPServerStdio(params=serper_mcp_server_params, client_session_timeout_seconds=30) as mcp:\n",
    "        agent = Agent(name=\"research-agent\", model=model, instructions=instructions, mcp_servers=[mcp], output_type=ResearchResults)\n",
    "        \n",
    "        result = await Runner.run(agent, request)\n",
    "\n",
    "    articles = result.final_output.articles\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fff59e",
   "metadata": {},
   "source": [
    "## Article Evaluation System\n",
    "\n",
    "This section implements an AI-powered article evaluation system using:\n",
    "\n",
    "- **Sentence Transformers**: Used to calculate embeddings\n",
    "- **Cosine Similarity**: Calculates similarity between articles and target topics\n",
    "- **Relevance Scoring**: Assigns relevance scores and best matching topics\n",
    "- **Topic Classification**: Automatically categorizes articles by topic\n",
    "\n",
    "The evaluation system ensures only relevant, high-quality articles are included in the final newsletter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5bdbd5",
   "metadata": {},
   "source": [
    "### Topic Classification System\n",
    "\n",
    "This section defines a comprehensive set of target topics for article classification:\n",
    "\n",
    "- **Funding & Investment**: Covers funding rounds, investments, IPOs, exits\n",
    "- **Industry-Specific**: Fintech, healthtech, edtech, AI, cybersecurity, etc.\n",
    "- **Geographic & Ecosystem**: Berlin, Munich, Hamburg startup scenes\n",
    "- **Technology & Innovation**: AI, blockchain, IoT, robotics, deep tech\n",
    "- **Business & Market**: Hiring, scaling, partnerships, growth\n",
    "- **Policy & Regulation**: Government support, visas, EU policy\n",
    "\n",
    "These topics are used for semantic similarity matching to evaluate article relevance and categorize content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e97dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_topics = [\n",
    "    # Funding & Investment\n",
    "    \"startups funding rounds\",\n",
    "    \"startup investments\", \n",
    "    \"venture capital news\",\n",
    "    \"startup Series A funding\",\n",
    "    \"startup seed funding\",\n",
    "    \"startup IPO news\",\n",
    "    \"startup exit deals\",\n",
    "    \"startup M&A activity\",\n",
    "    \"startup unicorn news\",\n",
    "    \n",
    "    # Industry-Specific\n",
    "    \"fintech startups\",\n",
    "    \"healthtech startups\",\n",
    "    \"edtech startups\", \n",
    "    \"proptech startups\",\n",
    "    \"cleantech startups\",\n",
    "    \"AI startups \",\n",
    "    \"cybersecurity startups\",\n",
    "    \"SaaS startups\",\n",
    "    \"biotech startups\",\n",
    "    \"mobility startups\",\n",
    "    \n",
    "    # Geographic & Ecosystem\n",
    "    \"Berlin startup ecosystem\",\n",
    "    \"Munich startup scene\", \n",
    "    \"Hamburg startups\",\n",
    "    \"startup accelerators\",\n",
    "    \"startup incubators\",\n",
    "    \"startup hubs\",\n",
    "    \"startup events\",\n",
    "    \"startup conferences\",\n",
    "    \n",
    "    # Technology & Innovation\n",
    "    \"AI innovation\",\n",
    "    \"machine learning startups\",\n",
    "    \"blockchain startups\",\n",
    "    \"IoT startups\",\n",
    "    \"robotics startups\",\n",
    "    \"deep tech startups\",\n",
    "    \"B2B startups\",\n",
    "    \"platform startups\",\n",
    "    \n",
    "    # Business & Market\n",
    "    \"startup hiring\",\n",
    "    \"startup talent\",\n",
    "    \"startup founders\",\n",
    "    \"startup scaling\",\n",
    "    \"startup growth\",\n",
    "    \"startup expansion\",\n",
    "    \"startup international\",\n",
    "    \"startup partnerships\",\n",
    "    \n",
    "    # Policy & Regulation\n",
    "    \"startup policy\",\n",
    "    \"startup regulation\",\n",
    "    \"startup visa\",\n",
    "    \"startup government support\",\n",
    "    \"startup EU policy\",\n",
    "    \"startup innovation policy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7cb609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "target_topic_embeddings = embedding_model.encode(target_topics)\n",
    "\n",
    "@observe(name=\"evaluate article\")\n",
    "def evaluate_article(article: Article) -> ArticleEvaluation:\n",
    "    article_embedding = embedding_model.encode(article.title + \" \" + article.summary)\n",
    "\n",
    "    article_embedding_2d = article_embedding.reshape(1, -1)\n",
    "\n",
    "    # Calculate similarity with all target topics\n",
    "    similarities = cosine_similarity(article_embedding_2d, target_topic_embeddings)\n",
    "\n",
    "    # Get the highest similarity score\n",
    "    max_similarity = float(np.max(similarities))\n",
    "    best_topic_idx = int(np.argmax(similarities))\n",
    "    best_topic = target_topics[best_topic_idx]\n",
    "\n",
    "    return ArticleEvaluation(\n",
    "        relevance_score=max_similarity,\n",
    "        best_matching_topic=best_topic\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134d37d9",
   "metadata": {},
   "source": [
    "## Article Summarization Pipeline\n",
    "\n",
    "This section implements the article analysis and summarization process:\n",
    "\n",
    "- **Content Fetching**: Uses MCP fetch server to retrieve full article content\n",
    "- **AI Summarization**: Analyzes articles and creates structured summaries\n",
    "- **Quality Control**: Combines summarization with relevance evaluation\n",
    "- **Report Generation**: Creates comprehensive article reports with scores and topics\n",
    "\n",
    "The analyst agent processes each article to extract key insights and create engaging, structured summaries for the newsletter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6535d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_mcp_server_params = {\"command\": \"uvx\", \"args\": [\"mcp-server-fetch\"]}\n",
    "\n",
    "instructions_summarize_article = \"You are a highly efficient analyst with a background in startup domain. You have a talent in presenting news and articles in a structured, easy-to-read, enganging and fun way. \\\n",
    "    Your sole purpose is to summarize news articles about German startups.\"\n",
    "\n",
    "@observe(name=\"analyst-agent - summarizing article\")\n",
    "async def summarize_article(article: Article) -> ArticleReport:\n",
    "    request_summarize_article = f\"Use your tool `fetch` to fetch the article by its `url`. \\\n",
    "        Analyse the article and create a insightful report, including all key take aways. The report should be easy-to-read und up to 150 words. \\\n",
    "        **Article**: {article}\"\n",
    "    \n",
    "    async with MCPServerStdio(params=fetch_mcp_server_params, client_session_timeout_seconds=30) as mcp:\n",
    "        agent = Agent(name=\"analyst-agent\", model=model, instructions=instructions_summarize_article, mcp_servers=[mcp], output_type=ArticleSummary)\n",
    "        \n",
    "        result = await Runner.run(agent, request_summarize_article)\n",
    "\n",
    "    article_summary = result.final_output\n",
    "    article_evaluation = evaluate_article(article_summary)\n",
    "\n",
    "    return ArticleReport(\n",
    "        title=article_summary.title,\n",
    "        date=article_summary.date,\n",
    "        url=article_summary.url,\n",
    "        summary=article_summary.summary,\n",
    "        relevance_score=article_evaluation.relevance_score,\n",
    "        best_matching_topic=article_evaluation.best_matching_topic\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb4dd95",
   "metadata": {},
   "source": [
    "## Newsletter Report Generation\n",
    "\n",
    "This section handles the final newsletter creation:\n",
    "\n",
    "- **Content Assembly**: Combines all analyzed articles into a structured newsletter\n",
    "- **Template Formatting**: Uses a predefined template with Introduction, TLDR, Articles, and Conclusion\n",
    "- **Markdown Generation**: Creates clean, formatted markdown output\n",
    "- **File Management**: Automatically saves reports with timestamps\n",
    "\n",
    "The reporter agent creates a professional newsletter format that's ready for publication or further editing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eee726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write up\n",
    "\n",
    "instructions_write_up = \"You are a highly efficient writer for a news team. Your sole purpose is to write up a the summarized articles in a structured way.\"\n",
    "\n",
    "@observe(name=\"reporter-agent - writing up report\")\n",
    "async def write_report(article_reports: list[ArticleReport]) -> str:\n",
    "    request_write_up = f\"Write up the following articles into a newsletter: {article_reports} \\\n",
    "        Follow the following template: \\\n",
    "        # Introduction \\\n",
    "        # TLDR \\\n",
    "        # Articles \\\n",
    "        # Per article: Headline, Date, Summary, Read more with Link, Relevance Score, Best Matching Topic \\\n",
    "        # Conclusion \\\n",
    "        Only return clean markdown, no other text.\"\n",
    "    \n",
    "    agent = Agent(name=\"reporter-agent\", model=model, instructions=instructions_write_up)\n",
    "        \n",
    "    result = await Runner.run(agent, request_write_up)\n",
    "\n",
    "    report_content = result.final_output\n",
    "\n",
    "     # Save to markdown file\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"newsletter_report_{timestamp}.md\"\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(report_content)\n",
    "    \n",
    "    print(f\"Report saved to: {filename}\")\n",
    "    \n",
    "    return report_content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73178b7",
   "metadata": {},
   "source": [
    "## Complete Research Pipeline\n",
    "\n",
    "This section orchestrates the entire research process:\n",
    "\n",
    "1. **Research Phase**: Finds relevant German startup articles using Google Search\n",
    "2. **Analysis Phase**: Summarizes and evaluates each article for relevance\n",
    "3. **Reporting Phase**: Generates a comprehensive newsletter report\n",
    "\n",
    "The pipeline runs asynchronously and includes observability through Langfuse tracing. The final output is a timestamped markdown file containing the complete newsletter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@observe(name=\"News research\")\n",
    "async def run_research():\n",
    "    articles = await research_article_urls(instructions, request)\n",
    "\n",
    "    article_summaries = []\n",
    "\n",
    "    for article in articles:\n",
    "        summary = await summarize_article(article)\n",
    "        article_summaries.append(summary)\n",
    "\n",
    "    report_content = await write_report(article_summaries)\n",
    "\n",
    "    return report_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae05d212",
   "metadata": {},
   "source": [
    "## Execution and Results\n",
    "\n",
    "This section executes the complete research pipeline and displays the results:\n",
    "\n",
    "- **Pipeline Execution**: Runs the full research, analysis, and reporting process\n",
    "- **Result Display**: Shows the generated newsletter in markdown format\n",
    "- **File Output**: Automatically saves the newsletter to a timestamped file\n",
    "- **Observability**: All steps are traced and monitored through Langfuse\n",
    "\n",
    "The final output is a comprehensive German startup newsletter ready for distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b44f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "loop = asyncio.get_running_loop()\n",
    "\n",
    "# Execute the function\n",
    "report_content = await loop.create_task(run_research())\n",
    "\n",
    "# Display the content\n",
    "display(Markdown(report_content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
